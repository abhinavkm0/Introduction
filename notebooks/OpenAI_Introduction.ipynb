{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac3d7b1",
   "metadata": {},
   "source": [
    "# OpenAI Introduction\n",
    "\n",
    "Use this for [reference](https://platform.openai.com/docs/api-reference/authentication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd25bac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pipenv install openai python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e56514",
   "metadata": {},
   "source": [
    "> Create an OpenAI account and get an API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f543321",
   "metadata": {},
   "source": [
    "### OpenAI:\n",
    "\n",
    "1. Chat completion API ✅\n",
    "2. Implement structured output ✅\n",
    "3. Implement tool calling ✅\n",
    "4. Implement streaming ✅\n",
    "5. Implement assistant\n",
    "6. Response API\n",
    "7. Chaining of response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e07b8812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82915665",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026dccaf",
   "metadata": {},
   "source": [
    "### List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0e7e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list()\n",
    "model_names = [model.id for model in models if \"gpt\" in model.id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "459f0e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-4o-audio-preview-2024-10-01',\n",
       " 'gpt-4o-mini-audio-preview',\n",
       " 'gpt-4o-audio-preview',\n",
       " 'gpt-4.1-nano',\n",
       " 'gpt-3.5-turbo-instruct-0914',\n",
       " 'gpt-4o-mini-search-preview',\n",
       " 'gpt-4.1-nano-2025-04-14',\n",
       " 'gpt-3.5-turbo-16k',\n",
       " 'gpt-3.5-turbo-1106',\n",
       " 'gpt-4o-search-preview',\n",
       " 'gpt-3.5-turbo-instruct',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-4o-mini-search-preview-2025-03-11',\n",
       " 'gpt-4o-2024-11-20',\n",
       " 'gpt-4o-2024-05-13',\n",
       " 'gpt-4o-mini-tts',\n",
       " 'gpt-4o-transcribe',\n",
       " 'gpt-4.5-preview',\n",
       " 'gpt-4.5-preview-2025-02-27',\n",
       " 'gpt-4o-search-preview-2025-03-11',\n",
       " 'gpt-image-1',\n",
       " 'gpt-4o',\n",
       " 'gpt-4o-2024-08-06',\n",
       " 'gpt-4o-mini-2024-07-18',\n",
       " 'gpt-4.1-mini',\n",
       " 'gpt-4o-mini',\n",
       " 'gpt-4o-mini-audio-preview-2024-12-17',\n",
       " 'gpt-3.5-turbo-0125',\n",
       " 'gpt-4o-mini-transcribe',\n",
       " 'gpt-4.1-mini-2025-04-14',\n",
       " 'gpt-4.1',\n",
       " 'gpt-4.1-2025-04-14']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f99367",
   "metadata": {},
   "source": [
    "| 1. Chat Completion |\n",
    "|--|\n",
    "\n",
    "\n",
    "The Chat Completions API endpoint will generate a model response from a list of messages comprising a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be71f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68c3963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=MODEL_NAME,\n",
    "  store=False,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"write a haiku about ai\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e36c2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines of code converge,  \n",
      "Whispers of thought and machine—  \n",
      "A mind yet to learn.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d1877",
   "metadata": {},
   "source": [
    "| 2. Structured Output |\n",
    "|--|\n",
    "\n",
    "Structured Outputs is a feature that ensures the model will always generate responses that adhere to your supplied JSON Schema,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipenv install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "959601f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93491fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserRegistration(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    tier: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94404453",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.beta.chat.completions.parse(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the user information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"We have a new user named Tim aged 25 with a tier 3 account.\"},\n",
    "    ],\n",
    "    response_format=UserRegistration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57b37cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserRegistration(name='Tim', age=25, tier=3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event = completion.choices[0].message.parsed\n",
    "event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133937da",
   "metadata": {},
   "source": [
    "| 3. Tool/Function Calling |\n",
    "|--|\n",
    "\n",
    "Function calling provides a powerful and flexible way for OpenAI models to interface with your code or external services. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9030b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current temperature for a given location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"City and country e.g. Bogotá, Colombia\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"location\"\n",
    "            ],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b6d26",
   "metadata": {},
   "source": [
    "| Function -> Tool JSON Convertor |\n",
    "|--|\n",
    "\n",
    "Automate tool JSON creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "63f5e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from typing import Callable, get_type_hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00fb5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_json_schema(func: Callable) -> str:\n",
    "    \"\"\"\n",
    "    Generate a JSON schema for a given function based on its docstring and type hints.\n",
    "\n",
    "    Args:\n",
    "        func (Callable): The Python function to generate a schema for.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string representing the function's schema.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the function lacks a docstring.\n",
    "    \"\"\"\n",
    "    # Get function metadata\n",
    "    if not func.__doc__:\n",
    "        raise ValueError(\"Function must have a docstring\")\n",
    "\n",
    "    signature = inspect.signature(func)\n",
    "    type_hints = get_type_hints(func)\n",
    "\n",
    "    # Parse docstring\n",
    "    docstring = inspect.getdoc(func) or \"\"\n",
    "    doc_lines = docstring.split('\\n')\n",
    "    description = doc_lines[0].strip()  # First line is the main description\n",
    "    param_descriptions = {}\n",
    "    in_args_section = False\n",
    "\n",
    "    # Extract parameter descriptions\n",
    "    for line in doc_lines:\n",
    "        line = line.strip()\n",
    "        if line.lower().startswith('args:'):\n",
    "            in_args_section = True\n",
    "            continue\n",
    "        if in_args_section and line and ':' in line:\n",
    "            # Handle lines like \"param_name (type): description\"\n",
    "            parts = line.split(':', 1)\n",
    "            param_part = parts[0].strip()\n",
    "            desc = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "            # Extract param_name from \"param_name (type)\"\n",
    "            if '(' in param_part and ')' in param_part:\n",
    "                param_name = param_part[:param_part.index('(')].strip()\n",
    "            else:\n",
    "                param_name = param_part\n",
    "            if param_name:\n",
    "                param_descriptions[param_name] = desc\n",
    "\n",
    "    # Map Python types to JSON schema types\n",
    "    type_mapping = {\n",
    "        'str': 'string',\n",
    "        'int': 'integer',\n",
    "        'float': 'number',\n",
    "        'bool': 'boolean',\n",
    "        'dict': 'object',\n",
    "        'list': 'array'\n",
    "    }\n",
    "\n",
    "    # Build schema\n",
    "    schema = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": func.__name__,\n",
    "            \"description\": description,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": [],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Add parameters to schema\n",
    "    for param_name, param in signature.parameters.items():\n",
    "        # Get type from type hints, default to str if not specified\n",
    "        param_type = type_hints.get(param_name, str).__name__\n",
    "        schema_type = type_mapping.get(param_type, 'string')  # Default to string\n",
    "        \n",
    "        schema[\"function\"][\"parameters\"][\"properties\"][param_name] = {\n",
    "            \"type\": schema_type,\n",
    "            \"description\": param_descriptions.get(param_name, f\"{param_name} parameter\")\n",
    "        }\n",
    "        # Mark as required if no default value\n",
    "        if param.default == inspect.Parameter.empty and param.kind != inspect.Parameter.VAR_KEYWORD:\n",
    "            schema[\"function\"][\"parameters\"][\"required\"].append(param_name)\n",
    "\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa6e45",
   "metadata": {},
   "source": [
    "#### Weather function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d5b784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get current temperature for a given location.\n",
    "\n",
    "    Args:\n",
    "        location (str): City and country e.g. Bogotá, Colombia\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the current temperature and other weather details.\n",
    "    \"\"\"\n",
    "    return {\"location\": location, \"temperature\": 25, \"unit\": \"Celsius\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4f28a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'get_weather',\n",
       "  'description': 'Get current temperature for a given location.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'location': {'type': 'string',\n",
       "     'description': 'City and country e.g. Bogotá, Colombia'}},\n",
       "   'required': ['location'],\n",
       "   'additionalProperties': False},\n",
       "  'strict': True}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_json_schema(func=get_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1548b12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'get_weather',\n",
       "  'description': 'Get current temperature for a given location.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'location': {'type': 'string',\n",
       "     'description': 'City and country e.g. Bogotá, Colombia'}},\n",
       "   'required': ['location'],\n",
       "   'additionalProperties': False},\n",
       "  'strict': True}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93146159",
   "metadata": {},
   "source": [
    "#### Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56bb0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the weather like in Paris today?\"}],\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "adcb8782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionMessageToolCall(id='call_I2B8aQ6ASMD15foX78hyFOvw', function=Function(arguments='{\"location\":\"Paris, France\"}', name='get_weather'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3afe1",
   "metadata": {},
   "source": [
    "| 4. Streaming |\n",
    "|--|\n",
    "\n",
    "\n",
    "Streaming responses lets you start printing or processing the beginning of the model's output while it continues generating the full response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "404e74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say 'double bubble bath' ten times fast.\",\n",
    "        },\n",
    "    ],\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4e4138e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content='Sure', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content='Sure', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' Here', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' Here', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' it', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' it', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' goes', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' goes', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=':', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=':', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' \"', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' \"', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content='double', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content='double', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' double', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bubble', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' bath', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content='.\"', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content='.\"', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' \\n\\n', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' \\n\\n', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content='That', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content='That', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' was', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' was', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' quite', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' quite', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' a', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' a', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' tongue', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' tongue', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=' tw', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=' tw', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content='ister', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content='ister', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content='!', function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n",
      "ChatCompletionChunk(id='chatcmpl-BbiPpqPC2l2GD2pCMomeKBZR2ByJ9', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None)], created=1748328569, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier='default', system_fingerprint='fp_54eb4bd693', usage=None)\n",
      "ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None)\n",
      "****************\n"
     ]
    }
   ],
   "source": [
    "for chunk in stream:\n",
    "    print(chunk)\n",
    "    print(chunk.choices[0].delta)\n",
    "    print(\"****************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f180a",
   "metadata": {},
   "source": [
    "| Assistants |\n",
    "|--|\n",
    "\n",
    "Build assistants that can call models and use tools to perform tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75ad6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a personal math tutor. When asked a question, write and run Python code to answer the question.\",\n",
    "    name=\"Math Tutor\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "40bd7378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asst_6gzaY6WEnSo3sEaWiHDfkv49\n"
     ]
    }
   ],
   "source": [
    "print(my_assistant.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "866a1b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Assistant(id='asst_6gzaY6WEnSo3sEaWiHDfkv49', created_at=1748328593, description=None, instructions='You are a personal math tutor. When asked a question, write and run Python code to answer the question.', metadata={}, model='gpt-4o-mini', name='Math Tutor', object='assistant', tools=[CodeInterpreterTool(type='code_interpreter')], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=ToolResourcesCodeInterpreter(file_ids=[]), file_search=None), top_p=1.0, reasoning_effort=None)]\n"
     ]
    }
   ],
   "source": [
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=\"20\",\n",
    ")\n",
    "print(my_assistants.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a54b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_assistant = client.beta.assistants.retrieve(assistant_id=my_assistant.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "895343cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asst_6gzaY6WEnSo3sEaWiHDfkv49'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_assistant.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062ce89",
   "metadata": {},
   "source": [
    "Create a Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b5899a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread ID: thread_NuxfP59uuYhnz5uZCmukGmgV\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "thread_id = thread.id\n",
    "print(f\"Thread ID: {thread_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "33ba5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread_id,\n",
    "    role=\"user\",\n",
    "    content=\"Explain factorial?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "90aa5751",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread_id,\n",
    "    assistant_id=my_assistant.id\n",
    ")\n",
    "\n",
    "# Wait for the run to complete\n",
    "import time\n",
    "while True:\n",
    "    run_status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)\n",
    "    if run_status.status == \"completed\":\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "33c0509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: A factorial, denoted by an exclamation mark (e.g., \\( n! \\)), is a mathematical operation that multiplies a positive integer \\( n \\) by all of the positive integers less than it down to 1. \n",
      "\n",
      "The factorial of a non-negative integer \\( n \\) can be defined as follows:\n",
      "\n",
      "- If \\( n = 0 \\), then \\( 0! = 1 \\) (by definition).\n",
      "- If \\( n > 0 \\), then \\( n! = n \\times (n-1) \\times (n-2) \\times \\ldots \\times 2 \\times 1 \\).\n",
      "\n",
      "For example:\n",
      "- \\( 5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120 \\)\n",
      "- \\( 3! = 3 \\times 2 \\times 1 = 6 \\)\n",
      "\n",
      "Factorials are commonly used in permutations, combinations, and other areas of mathematics, particularly in statistics and probability.\n",
      "\n",
      "Would you like to see how to calculate factorials using Python?\n"
     ]
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "for message in messages.data:\n",
    "    if message.role == \"assistant\":\n",
    "        print(f\"Assistant: {message.content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca8432",
   "metadata": {},
   "source": [
    "| 6. Response API |\n",
    "|--|\n",
    "\n",
    "Allow the model access to external systems and data using function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6af61461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the moon lit up the enchanted forest, Luna the unicorn spread her shimmering wings and soared through the starlit sky, painting dreams for all the sleeping children below.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b9d3a",
   "metadata": {},
   "source": [
    "Response API with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "739998c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of May 27, 2025, several positive environmental developments have been reported:\n",
      "\n",
      "1. **U.S. Introduces Limits on PFAS in Drinking Water**: The Environmental Protection Agency (EPA) has set its first-ever national legally enforceable limits on per- and polyfluoroalkyl substances (PFAS) in drinking water. This regulation aims to reduce PFAS exposure for approximately 100 million people by requiring public water systems to decrease contamination by 2029. ([homeplanet.grove.co](https://homeplanet.grove.co/blog-posts/positive-environmental-news-stories-that-give-us-hope-in-2025?utm_source=openai))\n",
      "\n",
      "2. **EU's Nature Restoration Law**: The European Union has enacted the Nature Restoration Law, a comprehensive initiative to restore damaged ecosystems and boost biodiversity. The law targets restoring 20% of the EU's land and sea areas by 2030 and all degraded ecosystems by 2050. ([homeplanet.grove.co](https://homeplanet.grove.co/blog-posts/positive-environmental-news-stories-that-give-us-hope-in-2025?utm_source=openai))\n",
      "\n",
      "3. **Record Sea Turtle Nests in Florida**: Anna Maria Island in Florida has reported a record 546 sea turtle nests, surpassing a 42-year-old record. This achievement highlights the success of long-term conservation efforts in protecting endangered species. ([homeplanet.grove.co](https://homeplanet.grove.co/blog-posts/positive-environmental-news-stories-that-give-us-hope-in-2025?utm_source=openai))\n",
      "\n",
      "4. **Montana Court Rules on Youth Climate Rights**: A Montana court ruled that the state's children have a \"fundamental constitutional right to a clean and healthful environment.\" This landmark decision underscores the growing influence of youth leadership in climate advocacy. ([homeplanet.grove.co](https://homeplanet.grove.co/blog-posts/positive-environmental-news-stories-that-give-us-hope-in-2025?utm_source=openai))\n",
      "\n",
      "5. **UK Closes Last Coal-Fired Power Plant**: The United Kingdom has closed its last coal-fired power plant, marking a significant step in its transition to cleaner energy sources. This move reflects the UK's commitment to reducing carbon emissions and combating climate change. ([homeplanet.grove.co](https://homeplanet.grove.co/blog-posts/positive-environmental-news-stories-that-give-us-hope-in-2025?utm_source=openai))\n",
      "\n",
      "These stories exemplify the global efforts and successes in environmental conservation and sustainability. \n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=MODEL_NAME,\n",
    "    tools=[{\"type\": \"web_search_preview\"}],\n",
    "    input=\"What was a positive news story from today?\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b80677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-bHz_lsOL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
